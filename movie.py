# -*- coding: utf-8 -*-
"""Movie.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PRCnkEY7SJ3t9jBxw4A7gyyzNCzj53Ex
"""

import pandas as pd

df = pd.read_csv('/content/test_data (1).csv')
display(df.head())

import pandas as pd

# Load the train and test datasets
train_df = pd.read_csv('/content/test_data (1).csv')
test_df = pd.read_csv('/content/test_data (1).csv')

# Rename the columns for clarity
train_df.columns = ['review', 'label']
test_df.columns = ['review', 'label']
# Check the first few rows to confirm the renaming
train_df.head()
test_df.head()

# Check for missing values
print("\nMissing Values in Train Data:")
print(train_df.isnull().sum())
# Summary statistics for the 'text' column
print("\nSummary Statistics for Text Column:")
print(train_df['review'].describe())
# Check the shape of the dataset
print(f"\nTrain Data Shape: {train_df.shape}")
print(f"Test Data Shape: {test_df.shape}")

import nltk
nltk.download('stopwords')
nltk.download('wordnet')

import string
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Initialize NLTK components
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    # Lowercase the text
    text = text.lower()

    # Remove punctuation and numbers
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)

    # Tokenize and remove stopwords
    words = text.split()
    words = [word for word in words if word not in stop_words]

    # Lemmatization
    words = [lemmatizer.lemmatize(word) for word in words]

    # Join the words back into a string
    cleaned_review = ' '.join(words)

    return cleaned_review

# Apply the cleaning function to the 'text' column
train_df['cleaned_review'] = train_df['review'].apply(clean_text)
test_df['cleaned_review'] = test_df['review'].apply(clean_text)

# Check the first few rows after cleaning
print("\nCleaned Text Sample:")
print(train_df[['review', 'cleaned_review']].head())

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

# Initialize vectorizers
bow_vectorizer = CountVectorizer()
tfidf_vectorizer = TfidfVectorizer()

# Apply BoW and TF-IDF to raw review
X_train_raw_bow = bow_vectorizer.fit_transform(train_df['review'])
X_test_raw_bow = bow_vectorizer.transform(test_df['review'])

X_train_raw_tfidf = tfidf_vectorizer.fit_transform(train_df['review'])
X_test_raw_tfidf = tfidf_vectorizer.transform(test_df['review'])

# Apply BoW and TF-IDF to cleaned review
X_train_clean_bow = bow_vectorizer.fit_transform(train_df['cleaned_review'])
X_test_clean_bow = bow_vectorizer.transform(test_df['cleaned_review'])

X_train_clean_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_review'])
X_test_clean_tfidf = tfidf_vectorizer.transform(test_df['cleaned_review'])

print(f"\nBoW Features for Raw review: {X_train_raw_bow.shape}")
print(f"BoW Features for Cleaned review: {X_train_clean_bow.shape}")
print(f"TF-IDF Features for Raw review: {X_train_raw_tfidf.shape}")
print(f"TF-IDF Features for Cleaned review: {X_train_clean_tfidf.shape}")

from sklearn.model_selection import train_test_split

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    train_df['review'], train_df['label'], test_size=0.2, random_state=42, stratify=train_df['label']
)

# Check the label distribution after splitting
print("\nTrain Label Distribution:")
print(y_train.value_counts())
print("\nTest Label Distribution:")
print(y_test.value_counts())

# Verify the shapes after splitting
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

# Apply BoW to raw text (train and test data)
X_train_raw_bow = bow_vectorizer.fit_transform(X_train)
X_test_raw_bow = bow_vectorizer.transform(X_test)

# Check the shapes of the resulting feature matrices
print(f"BoW Features for X_train (Raw Text): {X_train_raw_bow.shape}")
print(f"BoW Features for X_test (Raw Text): {X_test_raw_bow.shape}")

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from time import time

t = time()
duration = time() - t

# Initialize Naive Bayes model
naive_bayes_model = MultinomialNB()

# Train on BoW features for raw text
naive_bayes_model.fit(X_train_raw_bow, y_train)

training_time = time() - t
print("train time: %0.3fs" % training_time)

# Predict on test set
y_pred = naive_bayes_model.predict(X_test_raw_bow)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f"Naive Bayes Accuracy (BoW, Raw Text): {accuracy:.4f}")

# TF-IDF Features
X_train_raw_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_raw_tfidf = tfidf_vectorizer.transform(X_test)

# Train and Evaluate Naive Bayes with TF-IDF
naive_bayes_model.fit(X_train_raw_tfidf, y_train)
y_pred_tfidf = naive_bayes_model.predict(X_test_raw_tfidf)
accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)
print(f"Naive Bayes Accuracy (TF-IDF, Raw Text): {accuracy_tfidf:.4f}")

from sklearn.metrics import classification_report

print("\nClassification Report (TF-IDF, Raw Text):")
print(classification_report(y_test, y_pred_tfidf))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred_tfidf)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title('Confusion Matrix (TF-IDF, Raw Text)')
plt.show()

import joblib

# Save the trained model to a .pkl file
joblib.dump(naive_bayes_model, 'naive_bayes_model.pkl')

print("Trained model saved to naive_bayes_model.pkl")

"""## Load the trained model and tf-idf vectorizer

**Reasoning**:
Loading the trained Naive Bayes model and the fitted TF-IDF vectorizer using joblib.
"""

import joblib

# Load the trained Naive Bayes model
loaded_model = joblib.load('/content/naive_bayes_model.pkl')

# Load the fitted TF-IDF vectorizer
# Assuming the TF-IDF vectorizer was saved as 'tfidf_vectorizer.pkl' in a previous step.
loaded_tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')

print("Model and vectorizer loaded successfully.")

# Save the fitted TF-IDF vectorizer
joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')

# Now, load the trained Naive Bayes model and the fitted TF-IDF vectorizer
loaded_model = joblib.load('naive_bayes_model.pkl')
loaded_tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')

print("Model and vectorizer saved and loaded successfully.")

user_sentence = input("Please enter a sentence to predict its sentiment: ")

"""**Reasoning**:
Applying the cleaning function to the user input.


"""

cleaned_user_sentence = clean_text(user_sentence)
print(f"Cleaned sentence: {cleaned_user_sentence}")

"""**Reasoning**:
Transforming the cleaned user input into a numerical feature vector using the loaded tfidf_vectorizer.


"""

# Transform the cleaned user input into a numerical feature vector
vectorized_user_input = loaded_tfidf_vectorizer.transform([cleaned_user_sentence])

# Print the shape of the vectorized input
print(f"Shape of vectorized user input: {vectorized_user_input.shape}")

"""## Predict sentiment

**Reasoning**:
Using the loaded Naive Bayes model to predict the sentiment of the vectorized user input.
"""

# Use the loaded model to predict the sentiment
sentiment_prediction = loaded_model.predict(vectorized_user_input)

# Print the prediction
print(f"Predicted sentiment (0: Negative, 1: Positive): {sentiment_prediction[0]}")

if sentiment_prediction[0] == 0:
    print("Predicted sentiment: Negative")
elif sentiment_prediction[0] == 1:
    print("Predicted sentiment: Positive")